{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01-30-2025\n",
    "\n",
    "# HANDS-ON LAB: Acquiring and Processing Information on the World's Largest Banks\n",
    "\n",
    "# Project Scenario:\n",
    "#   You have been hired as a data engineer by research organization. Your boss has asked you \n",
    "# to create a code that can be used to compile the list of the top 10 largest banks in the world \n",
    "# ranked by market capitalization in billion USD. Further, the data needs to be transformed and stored \n",
    "# in GBP, EUR, and INR as well, in accordance with the exchange rate information that has been made \n",
    "# available to you as a CSV file. The processed information table is to be saved locally in a CSV\n",
    "# format and as a database table.\n",
    "\n",
    "#   Your job is to create an automated system to generate this information so that the same can be \n",
    "# executed in every financial quarter to prepare the report.\n",
    "\n",
    "# Particulars of the code to be made have been shared below.\n",
    "# Code name : banks_project.py\n",
    "# Data URL : https://en.wikipedia.org/wiki/List_of_largest_banks\n",
    "# Exchange rate CSV : https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv\n",
    "# Table attributes (upon extraction only) : Name, MC_USD_Billion\n",
    "# Table Attributes (final) : Name, MC_USD_Billion, MC_GBP_Billion, MC_EUR_Billion, MC_INR_Billion\n",
    "# Output CSV Path : ./Largest_banks_data.csv\n",
    "# Database name : Banks.db\n",
    "# Table name : Largest_banks\n",
    "# Log file : code_log.txt\n",
    "\n",
    "## Task 1:\n",
    "#           Write a function log_progress() to log the progress of the code at different stages in a file\n",
    "#       code_log.txt. Use the list of log points provided to create log entries as every stage of the code.\n",
    "\n",
    "## Task 2:\n",
    "#           Extract the tabular information from the given URL under the heading 'By Market Capitalization\n",
    "#       and save it to a dataframe.\n",
    "#           a. inspect the webage and indentify the position and pattern of the tabular information in the HTML code\n",
    "#           b. Write the code for a function extract()\n",
    "#           c. Execute a function call to extract() to verify the output\n",
    "\n",
    "## Task 3:\n",
    "#           Transform the dataframe by adding columns for Market Capitalization in GBP, EUR, and INR, rounded to 2\n",
    "#       decimal places, based on the exchange rate information shared in CSV file.\n",
    "#           a. Write the code for a function transform() to perform the said task.\n",
    "#           b. Execute a function call to transform() and verify the output.\n",
    "\n",
    "## Task 4:\n",
    "#           Load the transformed dataframe to an output CSV file. Write a function load_to_csv(), execute a function\n",
    "#       call and verify the output.\n",
    "\n",
    "## Task 5:\n",
    "#           Load the transformed dataframe to an SQL database server as a table. Write a function load_to_db(),\n",
    "#       execute a function call and verify the output.\n",
    "\n",
    "## Task 6:\n",
    "#           Run queries on the database table. Write a function load_to_db(), execute a given set of queries and\n",
    "#       verify the output.\n",
    "\n",
    "## Task 7:\n",
    "#           Verify that the log entries have been completed at all stages by checking the contents of the file\n",
    "#       code_log.txt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sqlite3 \n",
    "from datetime import datetime \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rank                                Bank name MC_USD_Billion  \\\n",
      "0    1                           JPMorgan Chase         432.92   \n",
      "1    2                          Bank of America         231.52   \n",
      "2    3  Industrial and Commercial Bank of China         194.56   \n",
      "3    4               Agricultural Bank of China         160.68   \n",
      "4    5                                HDFC Bank         157.91   \n",
      "\n",
      "   MC_GBP_Billion  MC_EUR_Billion  MC_INR_Billion  \n",
      "0          346.34          402.62        35910.71  \n",
      "1          185.22          215.31        19204.58  \n",
      "2          155.65          180.94        16138.75  \n",
      "3          128.54          149.43        13328.41  \n",
      "4          126.33          146.86        13098.63  \n",
      "   AVG(MC_GBP_Billion)\n",
      "0              151.987\n",
      "                                 Bank name\n",
      "0                           JPMorgan Chase\n",
      "1                          Bank of America\n",
      "2  Industrial and Commercial Bank of China\n",
      "3               Agricultural Bank of China\n",
      "4                                HDFC Bank\n"
     ]
    }
   ],
   "source": [
    "log_file = 'code_log.txt'\n",
    "exchange_rate = 'exchange_rate.csv'\n",
    "data_url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "\n",
    "# Task 1:\n",
    "def log_progress(log_msg):\n",
    "    timestamp_fmt = '%Y-%m-%d-%H:%M:%S' # timestamp format year-month-date-hour-min-sec\n",
    "    crnt_time = datetime.now() # current time\n",
    "    timestamp = crnt_time.strftime(timestamp_fmt)\n",
    "    with open(log_file, 'a') as log_f:\n",
    "        log_f.write(timestamp + ' : ' + log_msg + '\\n')\n",
    "\n",
    "def extract(url):\n",
    "    url_get = requests.get(url)\n",
    "    soup = BeautifulSoup(url_get.text, 'html.parser')\n",
    "    table = soup.find_all('table')[0]\n",
    "    table_headers = table.find_all('th')\n",
    "    bank_table_titles = []\n",
    "    for titles in table_headers:\n",
    "        bank_table_titles.append(titles.text.strip())\n",
    "    df = pd.DataFrame(columns=bank_table_titles)\n",
    "    column_data = table.find_all('tr')\n",
    "    for row in column_data[1:]:\n",
    "        bank_row_data = row.find_all('td')\n",
    "        per_row_bank_data = [data.text.strip() for data in bank_row_data]\n",
    "        df_length = len(df)\n",
    "        df.loc[df_length] = per_row_bank_data\n",
    "    return df\n",
    "\n",
    "def transform(df, csv_path):\n",
    "    df_2 = pd.read_csv(exchange_rate)\n",
    "    dict_df2_currency = df_2.set_index('Currency').to_dict()['Rate']\n",
    "    df.rename(columns={'Market cap(US$ billion)' : 'MC_USD_Billion' }, inplace=True)\n",
    "    df['MC_GBP_Billion'] = [np.round(x*dict_df2_currency['GBP'],2) for x in df['MC_USD_Billion'].astype(float)]\n",
    "    df['MC_EUR_Billion'] = [np.round(x*dict_df2_currency['EUR'],2) for x in df['MC_USD_Billion'].astype(float)]\n",
    "    df['MC_INR_Billion'] = [np.round(x*dict_df2_currency['INR'],2) for x in df['MC_USD_Billion'].astype(float)]\n",
    "    return df\n",
    "\n",
    "def load_to_csv(df, saveto_csv):\n",
    "    df.to_csv(saveto_csv)\n",
    "\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    sql_ = df.to_sql(table_name, sql_connection, if_exists = 'replace', index=False)\n",
    "    return sql_\n",
    "\n",
    "def run_queries(query_statement, sql_connection):\n",
    "    queries = pd.read_sql(query_statement, sql_connection)\n",
    "    return queries\n",
    "\n",
    "\n",
    "log_progress('Preliminaries complete. Initiating ETL process')\n",
    "\n",
    "x = extract(data_url)\n",
    "\n",
    "log_progress('Data extraction complete. Initiating Transformation process')\n",
    "\n",
    "y = transform(x, exchange_rate)\n",
    "\n",
    "log_progress('Data transformation complete. Initiating Loading process')\n",
    "\n",
    "z = load_to_csv(y, 'bank_mc.csv')\n",
    "\n",
    "log_progress('Data saved to CSV file')\n",
    "\n",
    "log_progress('SQL connection initiated')\n",
    "\n",
    "conn = sqlite3.connect('Banks.db')\n",
    "table_name = 'Largest_Banks'\n",
    "load_to_db(y, conn, table_name)\n",
    "\n",
    "log_progress('Data loaded to Database as a table, executing queries ....')\n",
    "\n",
    "statement = 'SELECT * from Largest_banks LIMIT 5'\n",
    "sql_query = run_queries(statement, conn)\n",
    "print(sql_query)\n",
    "statement = 'SELECT AVG(MC_GBP_Billion) from Largest_banks LIMIT 5'\n",
    "sql_query = run_queries(statement, conn)\n",
    "print(sql_query)\n",
    "statement = 'SELECT [Bank name] from Largest_banks LIMIT 5'\n",
    "sql_query = run_queries(statement, conn)\n",
    "print(sql_query)\n",
    "\n",
    "log_progress('Process complete')\n",
    "\n",
    "log_progress('Server connection closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
